import type { StructuredToolInterface } from '@langchain/core/tools';
import { convertToOpenAITool } from '@langchain/core/utils/function_calling';
import { Annotation, END, Send, START, StateGraph } from '@langchain/langgraph';
import OpenAI from 'openai';
import { zodResponseFormat } from 'openai/helpers/zod';
import type { ChatCompletionMessageParam } from 'openai/resources/chat/completions';

import type { Settings } from './configs.js';
import { setupLogger } from './custom-logger.js';
import {
  type AgentResult,
  planSchema,
  type ReflectionResult,
  reflectionResultSchema,
  type SearchOutput,
  type Subtask,
  type ToolResult,
} from './models.js';
import { HelpDeskAgentPrompts } from './prompts.js';

const MAX_CHALLENGE_COUNT = 3;

const logger = setupLogger('agent');

// ãƒ¡ã‚¤ãƒ³ã‚°ãƒ©ãƒ•ã®çŠ¶æ…‹å®šç¾©
const AgentStateAnnotation = Annotation.Root({
  question: Annotation<string>,
  plan: Annotation<string[]>,
  currentStep: Annotation<number>,
  subtaskResults: Annotation<Subtask[]>({
    reducer: (a: Subtask[], b: Subtask[]) => [...a, ...b],
    default: () => [],
  }),
  lastAnswer: Annotation<string>,
});

export type AgentState = typeof AgentStateAnnotation.State;

// ã‚µãƒ–ã‚°ãƒ©ãƒ•ã®çŠ¶æ…‹å®šç¾©
const AgentSubGraphStateAnnotation = Annotation.Root({
  question: Annotation<string>,
  plan: Annotation<string[]>,
  subtask: Annotation<string>,
  isCompleted: Annotation<boolean>,
  messages: Annotation<ChatCompletionMessageParam[]>({
    // æ–°ã—ã„å€¤ã§ä¸Šæ›¸ãï¼ˆaccumulateä¸è¦ã®ãŸã‚last write winsï¼‰
    reducer: (
      _old: ChatCompletionMessageParam[],
      newVal: ChatCompletionMessageParam[],
    ) => newVal,
    default: () => [],
  }),
  challengeCount: Annotation<number>,
  toolResults: Annotation<ToolResult[][]>({
    reducer: (a: ToolResult[][], b: ToolResult[][]) => [...a, ...b],
    default: () => [],
  }),
  reflectionResults: Annotation<ReflectionResult[]>({
    reducer: (a: ReflectionResult[], b: ReflectionResult[]) => [...a, ...b],
    default: () => [],
  }),
  subtaskAnswer: Annotation<string>,
});

export type AgentSubGraphState = typeof AgentSubGraphStateAnnotation.State;

export class HelpDeskAgent {
  private settings: Settings;
  private tools: StructuredToolInterface[];
  private toolMap: Map<string, StructuredToolInterface>;
  private prompts: HelpDeskAgentPrompts;
  private client: OpenAI;

  constructor(
    settings: Settings,
    tools: StructuredToolInterface[] = [],
    prompts: HelpDeskAgentPrompts = new HelpDeskAgentPrompts(),
  ) {
    this.settings = settings;
    this.tools = tools;
    this.toolMap = new Map(tools.map((tool) => [tool.name, tool]));
    this.prompts = prompts;
    this.client = new OpenAI({ apiKey: this.settings.openaiApiKey });
  }

  /**
   * è¨ˆç”»ã‚’ä½œæˆã™ã‚‹
   */
  async createPlan(state: AgentState): Promise<{ plan: string[] }> {
    logger.info('ğŸš€ Starting plan generation process...');

    const systemPrompt = this.prompts.plannerSystemPrompt;
    const userPrompt = this.prompts.plannerUserPrompt.replace(
      '{question}',
      state.question,
    );

    const messages: ChatCompletionMessageParam[] = [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userPrompt },
    ];
    logger.debug(`Final prompt messages: ${JSON.stringify(messages)}`);

    logger.info('Sending request to OpenAI...');
    const response = await this.client.chat.completions.parse({
      model: this.settings.openaiModel,
      messages,
      response_format: zodResponseFormat(planSchema, 'plan'),
      temperature: 0,
      seed: 0,
    });
    logger.info('âœ… Successfully received response from OpenAI.');

    const plan = response.choices[0]?.message.parsed ?? { subtasks: [] };

    logger.info('Plan generation complete!');

    return { plan: plan.subtasks };
  }

  /**
   * ãƒ„ãƒ¼ãƒ«ã‚’é¸æŠã™ã‚‹
   */
  async selectTools(
    state: AgentSubGraphState,
  ): Promise<{ messages: ChatCompletionMessageParam[] }> {
    logger.info('ğŸš€ Starting tool selection process...');

    // OpenAIå¯¾å¿œã®toolå®šç¾©ã«å¤‰æ›
    logger.debug('Converting tools for OpenAI format...');
    const openaiTools = this.tools.map((tool) => convertToOpenAITool(tool));

    let messages: ChatCompletionMessageParam[];

    if (state.challengeCount === 0) {
      logger.debug('Creating user prompt for tool selection...');
      const userPrompt = this.prompts.subtaskToolSelectionUserPrompt
        .replace('{question}', state.question)
        .replace('{plan}', JSON.stringify(state.plan))
        .replace('{subtask}', state.subtask);

      messages = [
        { role: 'system', content: this.prompts.subtaskSystemPrompt },
        { role: 'user', content: userPrompt },
      ];
    } else {
      logger.debug('Creating user prompt for tool retry...');

      // ãƒªãƒˆãƒ©ã‚¤ã•ã‚ŒãŸå ´åˆã¯éå»ã®å¯¾è©±æƒ…å ±ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¿½åŠ ã™ã‚‹
      // NOTE: ãƒˆãƒ¼ã‚¯ãƒ³æ•°ç¯€ç´„ã®ãŸã‚éå»ã®æ¤œç´¢çµæœã¯é™¤ã
      // roleãŒtoolã¾ãŸã¯tool_callsã‚’æŒã¤ã‚‚ã®ã¯é™¤ã
      messages = state.messages.filter(
        (message) => message.role !== 'tool' || !('tool_calls' in message),
      );

      const userRetryPrompt = this.prompts.subtaskRetryAnswerUserPrompt;
      messages.push({ role: 'user', content: userRetryPrompt });
    }

    logger.info('Sending request to OpenAI...');
    const response = await this.client.chat.completions.create({
      model: this.settings.openaiModel,
      messages,
      tools: openaiTools,
      temperature: 0,
      seed: 0,
    });
    logger.info('âœ… Successfully received response from OpenAI.');

    const selectChoice = response.choices[0];
    const toolCalls = selectChoice?.message.tool_calls;
    if (!toolCalls || toolCalls.length === 0) {
      // ãƒ¢ãƒ‡ãƒ«ãŒãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã°ãšã«ãƒ†ã‚­ã‚¹ãƒˆã§å¿œç­”ã—ãŸå ´åˆ
      logger.info('No tool calls returned, using text response as fallback.');
      const textContent = selectChoice?.message.content ?? '';
      messages.push({ role: 'assistant', content: textContent });
      return { messages };
    }

    const aiMessage: ChatCompletionMessageParam = {
      role: 'assistant',
      tool_calls: toolCalls,
    };

    logger.info('Tool selection complete!');
    messages.push(aiMessage);

    return { messages };
  }

  /**
   * ãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹
   */
  async executeTools(state: AgentSubGraphState): Promise<{
    messages: ChatCompletionMessageParam[];
    toolResults: ToolResult[][];
  }> {
    logger.info('ğŸš€ Starting tool execution process...');
    const messages = [...state.messages];

    const lastMessage = messages[messages.length - 1];
    const toolCalls =
      lastMessage?.role === 'assistant' && 'tool_calls' in lastMessage
        ? lastMessage.tool_calls
        : null;

    if (!toolCalls || toolCalls.length === 0) {
      // selectToolsã§ãƒ„ãƒ¼ãƒ«ãŒé¸æŠã•ã‚Œãªã‹ã£ãŸå ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
      logger.info('No tool calls found, skipping tool execution.');
      return { messages, toolResults: [[]] };
    }

    const toolResults: ToolResult[] = [];

    for (const toolCall of toolCalls) {
      if (toolCall.type !== 'function') {
        continue;
      }
      const toolName: string = toolCall.function.name;
      const toolArgs: string = toolCall.function.arguments;

      const tool = this.toolMap.get(toolName);
      if (!tool) {
        throw new Error(`Tool not found: ${toolName}`);
      }
      const toolResult: SearchOutput[] = await tool.invoke(
        JSON.parse(toolArgs),
      );

      toolResults.push({
        toolName,
        args: toolArgs,
        results: toolResult,
      });

      messages.push({
        role: 'tool',
        content: JSON.stringify(toolResult),
        tool_call_id: toolCall.id,
      });
    }
    logger.info('Tool execution complete!');
    return { messages, toolResults: [toolResults] };
  }

  /**
   * ã‚µãƒ–ã‚¿ã‚¹ã‚¯å›ç­”ã‚’ä½œæˆã™ã‚‹
   */
  async createSubtaskAnswer(state: AgentSubGraphState): Promise<{
    messages: ChatCompletionMessageParam[];
    subtaskAnswer: string;
  }> {
    logger.info('ğŸš€ Starting subtask answer creation process...');
    const messages = [...state.messages];

    logger.info('Sending request to OpenAI...');
    const response = await this.client.chat.completions.create({
      model: this.settings.openaiModel,
      messages,
      temperature: 0,
      seed: 0,
    });
    logger.info('âœ… Successfully received response from OpenAI.');

    const subtaskAnswer = response.choices[0]?.message.content ?? '';

    const aiMessage: ChatCompletionMessageParam = {
      role: 'assistant',
      content: subtaskAnswer,
    };
    messages.push(aiMessage);

    logger.info('Subtask answer creation complete!');

    return { messages, subtaskAnswer };
  }

  /**
   * ã‚µãƒ–ã‚¿ã‚¹ã‚¯å›ç­”ã‚’å†…çœã™ã‚‹
   */
  async reflectSubtask(state: AgentSubGraphState): Promise<{
    messages: ChatCompletionMessageParam[];
    reflectionResults: ReflectionResult[];
    challengeCount: number;
    isCompleted: boolean;
    subtaskAnswer?: string;
  }> {
    logger.info('ğŸš€ Starting reflection process...');
    const messages = [...state.messages];

    const userPrompt = this.prompts.subtaskReflectionUserPrompt;
    messages.push({ role: 'user', content: userPrompt });

    logger.info('Sending request to OpenAI...');
    const response = await this.client.chat.completions.parse({
      model: this.settings.openaiModel,
      messages,
      response_format: zodResponseFormat(
        reflectionResultSchema,
        'reflection_result',
      ),
      temperature: 0,
      seed: 0,
    });
    logger.info('âœ… Successfully received response from OpenAI.');

    const reflectionResult = response.choices[0]?.message.parsed ?? {
      advice: '',
      isCompleted: false,
    };

    messages.push({
      role: 'assistant',
      content: JSON.stringify(reflectionResult),
    });

    const updateState: {
      messages: ChatCompletionMessageParam[];
      reflectionResults: ReflectionResult[];
      challengeCount: number;
      isCompleted: boolean;
      subtaskAnswer?: string;
    } = {
      messages,
      reflectionResults: [reflectionResult],
      challengeCount: state.challengeCount + 1,
      isCompleted: reflectionResult.isCompleted,
    };

    if (
      updateState.challengeCount >= MAX_CHALLENGE_COUNT &&
      !reflectionResult.isCompleted
    ) {
      updateState.subtaskAnswer = `${state.subtask}ã®å›ç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚`;
    }

    logger.info('Reflection complete!');
    return updateState;
  }

  /**
   * æœ€çµ‚å›ç­”ã‚’ä½œæˆã™ã‚‹
   */
  async createAnswer(state: AgentState): Promise<{ lastAnswer: string }> {
    logger.info('ğŸš€ Starting final answer creation process...');
    const systemPrompt = this.prompts.createLastAnswerSystemPrompt;

    // ã‚µãƒ–ã‚¿ã‚¹ã‚¯çµæœã®ã†ã¡ã‚¿ã‚¹ã‚¯å†…å®¹ã¨å›ç­”ã®ã¿ã‚’å–å¾—
    const subtaskResults = state.subtaskResults.map((result) => [
      result.taskName,
      result.subtaskAnswer,
    ]);
    const userPrompt = this.prompts.createLastAnswerUserPrompt
      .replace('{question}', state.question)
      .replace('{subtask_results}', JSON.stringify(subtaskResults));

    const messages: ChatCompletionMessageParam[] = [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userPrompt },
    ];

    logger.info('Sending request to OpenAI...');
    const response = await this.client.chat.completions.create({
      model: this.settings.openaiModel,
      messages,
      temperature: 0,
      seed: 0,
    });
    logger.info('âœ… Successfully received response from OpenAI.');

    logger.info('Final answer creation complete!');

    return { lastAnswer: response.choices[0]?.message.content ?? '' };
  }

  /**
   * ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã‚’ã‚µãƒ–ã‚°ãƒ©ãƒ•ã§å®Ÿè¡Œã—ã€çµæœã‚’è¿”ã™
   * @param state - ãƒ¡ã‚¤ãƒ³ã‚°ãƒ©ãƒ•ã®ç¾åœ¨ã®çŠ¶æ…‹
   * @returns ã‚µãƒ–ã‚¿ã‚¹ã‚¯å®Ÿè¡Œçµæœã®é…åˆ—
   */
  private async executeSubgraph(state: AgentState) {
    const subgraph = this.createSubgraph();

    const result = await subgraph.invoke({
      question: state.question,
      plan: state.plan,
      subtask: state.plan[state.currentStep] ?? '',
      isCompleted: false,
      challengeCount: 0,
    });

    const subtaskResult: Subtask = {
      taskName: result.subtask,
      toolResults: result.toolResults,
      reflectionResults: result.reflectionResults,
      isCompleted: result.isCompleted,
      subtaskAnswer: result.subtaskAnswer,
      challengeCount: result.challengeCount,
    };

    return { subtaskResults: [subtaskResult] };
  }

  /**
   * è¨ˆç”»å†…ã®å„ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã‚’ä¸¦åˆ—å®Ÿè¡Œã™ã‚‹ãŸã‚ã®Sendãƒªã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹
   * @param state - ãƒ¡ã‚¤ãƒ³ã‚°ãƒ©ãƒ•ã®ç¾åœ¨ã®çŠ¶æ…‹
   * @returns å„ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã™ã‚‹Sendã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®é…åˆ—
   */
  private shouldContinueExecSubtasks(state: AgentState): Send[] {
    return state.plan.map(
      (_, idx) =>
        new Send('execute_subtasks', {
          question: state.question,
          plan: state.plan,
          currentStep: idx,
        }),
    );
  }

  /**
   * ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã®å®Ÿè¡Œãƒ•ãƒ­ãƒ¼ã‚’ç¶™ç¶šã™ã‚‹ã‹çµ‚äº†ã™ã‚‹ã‹åˆ¤å®šã™ã‚‹
   * @param state - ã‚µãƒ–ã‚°ãƒ©ãƒ•ã®ç¾åœ¨ã®çŠ¶æ…‹
   * @returns ç¶™ç¶šã™ã‚‹å ´åˆã¯'continue'ã€çµ‚äº†ã™ã‚‹å ´åˆã¯'end'
   */
  private shouldContinueExecSubtaskFlow(
    state: AgentSubGraphState,
  ): 'end' | 'continue' {
    if (state.isCompleted || state.challengeCount >= MAX_CHALLENGE_COUNT) {
      return 'end';
    }
    return 'continue';
  }

  /**
   * ã‚µãƒ–ã‚°ãƒ©ãƒ•ã‚’ä½œæˆã™ã‚‹
   */
  private createSubgraph() {
    // ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã§ãƒãƒ¼ãƒ‰ã¨ã‚¨ãƒƒã‚¸ã‚’è¿½åŠ ï¼ˆå‹æ¨è«–ã®ãŸã‚ï¼‰
    return new StateGraph(AgentSubGraphStateAnnotation)
      .addNode('select_tools', (state) => this.selectTools(state))
      .addNode('execute_tools', (state) => this.executeTools(state))
      .addNode('create_subtask_answer', (state) =>
        this.createSubtaskAnswer(state),
      )
      .addNode('reflect_subtask', (state) => this.reflectSubtask(state))
      .addEdge(START, 'select_tools')
      .addEdge('select_tools', 'execute_tools')
      .addEdge('execute_tools', 'create_subtask_answer')
      .addEdge('create_subtask_answer', 'reflect_subtask')
      .addConditionalEdges(
        'reflect_subtask',
        (state) => this.shouldContinueExecSubtaskFlow(state),
        { continue: 'select_tools', end: END },
      )
      .compile();
  }

  /**
   * ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ¡ã‚¤ãƒ³ã‚°ãƒ©ãƒ•ã‚’ä½œæˆã™ã‚‹
   */
  createGraph() {
    // ãƒ¡ã‚½ãƒƒãƒ‰ãƒã‚§ãƒ¼ãƒ³ã§ãƒãƒ¼ãƒ‰ã¨ã‚¨ãƒƒã‚¸ã‚’è¿½åŠ ï¼ˆå‹æ¨è«–ã®ãŸã‚ï¼‰
    return new StateGraph(AgentStateAnnotation)
      .addNode('create_plan', (state) => this.createPlan(state))
      .addNode('execute_subtasks', (state) => this.executeSubgraph(state))
      .addNode('create_answer', (state) => this.createAnswer(state))
      .addEdge(START, 'create_plan')
      .addConditionalEdges('create_plan', (state) =>
        this.shouldContinueExecSubtasks(state),
      )
      .addEdge('execute_subtasks', 'create_answer')
      .addEdge('create_answer', END)
      .compile();
  }

  /**
   * ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œã™ã‚‹.
   */
  async runAgent(question: string): Promise<AgentResult> {
    const app = this.createGraph();
    const result = await app.invoke({
      question,
      currentStep: 0,
    });

    return {
      question,
      plan: { subtasks: result.plan },
      subtasks: result.subtaskResults,
      answer: result.lastAnswer,
    };
  }
}
