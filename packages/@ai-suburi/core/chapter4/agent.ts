import OpenAI from 'openai';
import { zodResponseFormat } from 'openai/helpers/zod';
import { Annotation, END, START, StateGraph, Send } from '@langchain/langgraph';
import type { Settings } from './configs.js';
import { setupLogger } from './logger.js';
import {
  PlanSchema,
  ReflectionResultSchema,
} from './models.js';
import type {
  AgentResult,
  AgentTool,
  ReflectionResult,
  Subtask,
  ToolResult,
} from './models.js';
import { HelpDeskAgentPrompts } from './prompts.js';

const MAX_CHALLENGE_COUNT = 3;

const logger = setupLogger('agent');

// --- ãƒ¡ã‚¤ãƒ³ã‚°ãƒ©ãƒ•ã®çŠ¶æ…‹å®šç¾© ---

const AgentStateAnnotation = Annotation.Root({
  question: Annotation<string>,
  plan: Annotation<string[]>,
  current_step: Annotation<number>,
  subtask_results: Annotation<Subtask[]>({
    reducer: (current, update) => [...current, ...update],
    default: () => [],
  }),
  last_answer: Annotation<string>,
});

type AgentStateType = typeof AgentStateAnnotation.State;

// --- ã‚µãƒ–ã‚°ãƒ©ãƒ•ã®çŠ¶æ…‹å®šç¾© ---

const AgentSubGraphStateAnnotation = Annotation.Root({
  question: Annotation<string>,
  plan: Annotation<string[]>,
  subtask: Annotation<string>,
  is_completed: Annotation<boolean>,
  messages: Annotation<OpenAI.ChatCompletionMessageParam[]>({
    reducer: (_current, update) => update,
    default: () => [],
  }),
  challenge_count: Annotation<number>,
  tool_results: Annotation<ToolResult[][]>({
    reducer: (current, update) => [...current, ...update],
    default: () => [],
  }),
  reflection_results: Annotation<ReflectionResult[]>({
    reducer: (current, update) => [...current, ...update],
    default: () => [],
  }),
  subtask_answer: Annotation<string>,
});

type AgentSubGraphStateType = typeof AgentSubGraphStateAnnotation.State;

// --- ãƒ˜ãƒ«ãƒ—ãƒ‡ã‚¹ã‚¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¯ãƒ©ã‚¹ ---

export class HelpDeskAgent {
  private settings: Settings;
  private tools: AgentTool[];
  private toolMap: Map<string, AgentTool>;
  private prompts: HelpDeskAgentPrompts;
  private client: OpenAI;

  constructor(
    settings: Settings,
    tools: AgentTool[] = [],
    prompts: HelpDeskAgentPrompts = new HelpDeskAgentPrompts(),
  ) {
    this.settings = settings;
    this.tools = tools;
    this.toolMap = new Map(tools.map((t) => [t.name, t]));
    this.prompts = prompts;
    this.client = new OpenAI({ apiKey: this.settings.openaiApiKey });
  }

  /**
   * è¨ˆç”»ã‚’ä½œæˆã™ã‚‹
   */
  async createPlan(state: AgentStateType): Promise<Partial<AgentStateType>> {
    logger.info('ğŸš€ Starting plan generation process...');

    const systemPrompt = this.prompts.plannerSystemPrompt;
    const userPrompt = this.prompts.formatPlannerUserPrompt({
      question: state.question,
    });

    const messages: OpenAI.ChatCompletionMessageParam[] = [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userPrompt },
    ];
    logger.debug(`Final prompt messages: ${JSON.stringify(messages)}`);

    try {
      logger.info('Sending request to OpenAI...');
      const response = await this.client.chat.completions.parse({
        model: this.settings.openaiModel,
        messages,
        response_format: zodResponseFormat(PlanSchema, 'Plan'),
      });
      logger.info('âœ… Successfully received response from OpenAI.');

      const plan = response.choices[0]?.message.parsed;
      if (!plan) {
        throw new Error('Plan parsing returned null');
      }

      logger.info('Plan generation complete!');
      return { plan: plan.subtasks };
    } catch (e) {
      logger.error(`Error during OpenAI request: ${e}`);
      throw e;
    }
  }

  /**
   * ãƒ„ãƒ¼ãƒ«ã‚’é¸æŠã™ã‚‹
   */
  async selectTools(state: AgentSubGraphStateType): Promise<Partial<AgentSubGraphStateType>> {
    logger.info('ğŸš€ Starting tool selection process...');

    const openaiTools = this.tools.map((t) => t.definition);

    let messages: OpenAI.ChatCompletionMessageParam[];

    if (state.challenge_count === 0) {
      logger.debug('Creating user prompt for tool selection...');
      const userPrompt = this.prompts.formatSubtaskToolSelectionUserPrompt({
        question: state.question,
        plan: JSON.stringify(state.plan),
        subtask: state.subtask,
      });

      messages = [
        { role: 'system', content: this.prompts.subtaskSystemPrompt },
        { role: 'user', content: userPrompt },
      ];
    } else {
      logger.debug('Creating user prompt for tool retry...');

      // ãƒªãƒˆãƒ©ã‚¤ã•ã‚ŒãŸå ´åˆã¯éå»ã®å¯¾è©±æƒ…å ±ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¿½åŠ ã™ã‚‹
      // NOTE: ãƒˆãƒ¼ã‚¯ãƒ³æ•°ç¯€ç´„ã®ãŸã‚éå»ã®æ¤œç´¢çµæœã¯é™¤ã
      // roleãŒtoolã¾ãŸã¯tool_callsã‚’æŒã¤ã‚‚ã®ã¯é™¤ã
      messages = state.messages.filter(
        (m) => m.role !== 'tool' || !('tool_calls' in m),
      );

      const userRetryPrompt = this.prompts.subtaskRetryAnswerUserPrompt;
      messages.push({ role: 'user', content: userRetryPrompt });
    }

    try {
      logger.info('Sending request to OpenAI...');
      const response = await this.client.chat.completions.create({
        model: this.settings.openaiModel,
        messages,
        tools: openaiTools,
      });
      logger.info('âœ… Successfully received response from OpenAI.');
      logger.info(JSON.stringify(response, null, 2));
      
      const toolCalls = response.choices[0]?.message.tool_calls;
      if (!toolCalls) {
        throw new Error('Tool calls are None');
      }

      // functionå‹ã®tool callã®ã¿ã‚’å–å¾—
      const functionToolCalls = toolCalls.filter(
        (tc): tc is OpenAI.ChatCompletionMessageFunctionToolCall => tc.type === 'function',
      );

      const aiMessage: OpenAI.ChatCompletionAssistantMessageParam = {
        role: 'assistant',
        tool_calls: functionToolCalls,
      };

      logger.info('Tool selection complete!');
      messages.push(aiMessage);

      return { messages };
    } catch (e) {
      logger.error(`Error during OpenAI request: ${e}`);
      throw e;
    }
  }

  /**
   * ãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹
   */
  async executeTools(state: AgentSubGraphStateType): Promise<Partial<AgentSubGraphStateType>> {
    logger.info('ğŸš€ Starting tool execution process...');
    const messages = [...state.messages];

    const lastMessage = messages[messages.length - 1];
    if (!lastMessage || lastMessage.role !== 'assistant' || !('tool_calls' in lastMessage)) {
      logger.error(`Messages: ${JSON.stringify(messages)}`);
      throw new Error('Tool calls are None');
    }

    const allToolCalls = (lastMessage as OpenAI.ChatCompletionAssistantMessageParam).tool_calls;
    if (!allToolCalls) {
      throw new Error('Tool calls are None');
    }

    // functionå‹ã®tool callã®ã¿ã‚’å‡¦ç†
    const toolCalls = allToolCalls.filter(
      (tc): tc is OpenAI.ChatCompletionMessageFunctionToolCall => tc.type === 'function',
    );

    const toolResults: ToolResult[] = [];

    for (const toolCall of toolCalls) {
      const toolName = toolCall.function.name;
      const toolArgsStr = toolCall.function.arguments;
      const toolArgs = JSON.parse(toolArgsStr) as Record<string, unknown>;

      const tool = this.toolMap.get(toolName);
      if (!tool) {
        throw new Error(`Tool not found: ${toolName}`);
      }

      const result = await tool.invoke(toolArgs);

      toolResults.push({
        tool_name: toolName,
        args: toolArgsStr,
        results: result,
      });

      messages.push({
        role: 'tool',
        content: JSON.stringify(result),
        tool_call_id: toolCall.id,
      });
    }

    logger.info('Tool execution complete!');
    return { messages, tool_results: [toolResults] };
  }

  /**
   * ã‚µãƒ–ã‚¿ã‚¹ã‚¯å›ç­”ã‚’ä½œæˆã™ã‚‹
   */
  async createSubtaskAnswer(state: AgentSubGraphStateType): Promise<Partial<AgentSubGraphStateType>> {
    logger.info('ğŸš€ Starting subtask answer creation process...');
    const messages = [...state.messages];

    try {
      logger.info('Sending request to OpenAI...');
      const response = await this.client.chat.completions.create({
        model: this.settings.openaiModel,
        messages,
      });
      logger.info('âœ… Successfully received response from OpenAI.');

      const subtaskAnswer = response.choices[0]?.message.content ?? '';

      messages.push({ role: 'assistant', content: subtaskAnswer });

      logger.info('Subtask answer creation complete!');
      return { messages, subtask_answer: subtaskAnswer };
    } catch (e) {
      logger.error(`Error during OpenAI request: ${e}`);
      throw e;
    }
  }

  /**
   * ã‚µãƒ–ã‚¿ã‚¹ã‚¯å›ç­”ã‚’å†…çœã™ã‚‹
   */
  async reflectSubtask(state: AgentSubGraphStateType): Promise<Partial<AgentSubGraphStateType>> {
    logger.info('ğŸš€ Starting reflection process...');
    const messages = [...state.messages];

    const userPrompt = this.prompts.subtaskReflectionUserPrompt;
    messages.push({ role: 'user', content: userPrompt });

    try {
      logger.info('Sending request to OpenAI...');
      const response = await this.client.chat.completions.parse({
        model: this.settings.openaiModel,
        messages,
        response_format: zodResponseFormat(ReflectionResultSchema, 'ReflectionResult'),
      });
      logger.info('âœ… Successfully received response from OpenAI.');

      const reflectionResult = response.choices[0]?.message.parsed;
      if (!reflectionResult) {
        throw new Error('Reflection result is None');
      }

      messages.push({
        role: 'assistant',
        content: JSON.stringify(reflectionResult),
      });

      const newChallengeCount = state.challenge_count + 1;
      const updateState: Partial<AgentSubGraphStateType> = {
        messages,
        reflection_results: [reflectionResult],
        challenge_count: newChallengeCount,
        is_completed: reflectionResult.is_completed,
      };

      if (newChallengeCount >= MAX_CHALLENGE_COUNT && !reflectionResult.is_completed) {
        updateState.subtask_answer = `${state.subtask}ã®å›ç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚`;
      }

      logger.info('Reflection complete!');
      return updateState;
    } catch (e) {
      logger.error(`Error during OpenAI request: ${e}`);
      throw e;
    }
  }

  /**
   * æœ€çµ‚å›ç­”ã‚’ä½œæˆã™ã‚‹
   */
  async createAnswer(state: AgentStateType): Promise<Partial<AgentStateType>> {
    logger.info('ğŸš€ Starting final answer creation process...');

    const systemPrompt = this.prompts.createLastAnswerSystemPrompt;

    const subtaskResults = state.subtask_results.map((result) => [
      result.task_name,
      result.subtask_answer,
    ]);
    const userPrompt = this.prompts.formatCreateLastAnswerUserPrompt({
      question: state.question,
      subtask_results: JSON.stringify(subtaskResults),
    });

    const messages: OpenAI.ChatCompletionMessageParam[] = [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userPrompt },
    ];

    try {
      logger.info('Sending request to OpenAI...');
      const response = await this.client.chat.completions.create({
        model: this.settings.openaiModel,
        messages,
      });
      logger.info('âœ… Successfully received response from OpenAI.');

      logger.info('Final answer creation complete!');
      return { last_answer: response.choices[0]?.message.content ?? '' };
    } catch (e) {
      logger.error(`Error during OpenAI request: ${e}`);
      throw e;
    }
  }

  /**
   * ã‚µãƒ–ã‚°ãƒ©ãƒ•ã‚’å®Ÿè¡Œã™ã‚‹ï¼ˆãƒ¡ã‚¤ãƒ³ã‚°ãƒ©ãƒ•ã®ãƒãƒ¼ãƒ‰ï¼‰
   */
  private async executeSubgraph(state: AgentStateType): Promise<Partial<AgentStateType>> {
    const subgraph = this.createSubgraph();

    const result = await subgraph.invoke({
      question: state.question,
      plan: state.plan,
      subtask: state.plan[state.current_step]!,
      is_completed: false,
      challenge_count: 0,
      messages: [],
      subtask_answer: '',
    });

    const subtaskResult: Subtask = {
      task_name: result.subtask,
      tool_results: result.tool_results,
      reflection_results: result.reflection_results,
      is_completed: result.is_completed,
      subtask_answer: result.subtask_answer,
      challenge_count: result.challenge_count,
    };

    return { subtask_results: [subtaskResult] };
  }

  /**
   * ã‚µãƒ–ã‚¿ã‚¹ã‚¯å®Ÿè¡Œã®ç¶™ç¶šåˆ¤å®šï¼ˆSend ã§ä¸¦åˆ—å®Ÿè¡Œï¼‰
   */
  private shouldContinueExecSubtasks(state: AgentStateType): Send[] {
    return state.plan.map(
      (_, idx) =>
        new Send('execute_subtasks', {
          question: state.question,
          plan: state.plan,
          current_step: idx,
        }),
    );
  }

  /**
   * ã‚µãƒ–ã‚¿ã‚¹ã‚¯ãƒ•ãƒ­ãƒ¼ã®ç¶™ç¶šåˆ¤å®š
   */
  private shouldContinueExecSubtaskFlow(state: AgentSubGraphStateType): string {
    if (state.is_completed || state.challenge_count >= MAX_CHALLENGE_COUNT) {
      return 'end';
    }
    return 'continue';
  }

  /**
   * ã‚µãƒ–ã‚°ãƒ©ãƒ•ã‚’ä½œæˆã™ã‚‹
   */
  private createSubgraph() {
    const workflow = new StateGraph(AgentSubGraphStateAnnotation)
      .addNode('select_tools', async (state) => this.selectTools(state))
      .addNode('execute_tools', async (state) => this.executeTools(state))
      .addNode('create_subtask_answer', async (state) => this.createSubtaskAnswer(state))
      .addNode('reflect_subtask', async (state) => this.reflectSubtask(state))
      .addEdge(START, 'select_tools')
      .addEdge('select_tools', 'execute_tools')
      .addEdge('execute_tools', 'create_subtask_answer')
      .addEdge('create_subtask_answer', 'reflect_subtask')
      .addConditionalEdges(
        'reflect_subtask',
        (state) => this.shouldContinueExecSubtaskFlow(state),
        { continue: 'select_tools', end: END },
      );

    return workflow.compile();
  }

  /**
   * ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ¡ã‚¤ãƒ³ã‚°ãƒ©ãƒ•ã‚’ä½œæˆã™ã‚‹
   */
  createGraph() {
    const workflow = new StateGraph(AgentStateAnnotation)
      .addNode('create_plan', async (state) => this.createPlan(state))
      .addNode('execute_subtasks', async (state) => this.executeSubgraph(state))
      .addNode('create_answer', async (state) => this.createAnswer(state))
      .addEdge(START, 'create_plan')
      .addConditionalEdges('create_plan', (state) => this.shouldContinueExecSubtasks(state))
      .addEdge('execute_subtasks', 'create_answer')
      .addEdge('create_answer', END);

    return workflow.compile();
  }

  /**
   * ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œã™ã‚‹
   */
  async runAgent(question: string): Promise<AgentResult> {
    /**
      ã“ã‚Œã¯ LangGraphã§ä½œã£ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ¡ã‚¤ãƒ³ã‚°ãƒ©ãƒ•ã‚’åˆæœŸçŠ¶æ…‹ã§èµ·å‹•ã—ã¦ã‚‹ ã¨ã“ã ã‚ˆï¼
      const app = this.createGraph();
      createGraph() ã§ä½œã‚‰ã‚ŒãŸ LangGraphã®ã‚¹ãƒ†ãƒ¼ãƒˆãƒã‚·ãƒ³ï¼ˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ï¼‰ ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€‚ä¸­èº«ã¯ã“ã®æµã‚ŒğŸ‘‡
      START â†’ create_plan â†’ execute_subtasks(ä¸¦åˆ—) â†’ create_answer â†’ END

      invoke() ã£ã¦ä½•ï¼Ÿ
      ãã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ æœ€åˆã‹ã‚‰æœ€å¾Œã¾ã§å®Ÿè¡Œã™ã‚‹ ãƒ¡ã‚½ãƒƒãƒ‰ã€‚ å¼•æ•°ã¯ åˆæœŸã‚¹ãƒ†ãƒ¼ãƒˆï¼ˆçŠ¶æ…‹ï¼‰ ã‚’æ¸¡ã—ã¦ã‚‹ã®ã€‚

      1. åˆæœŸçŠ¶æ…‹ { question: "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã®åˆ¶é™ã¯ï¼Ÿ", plan: [], ... } ã§ã‚¹ã‚¿ãƒ¼ãƒˆ
      2. create_plan ãƒãƒ¼ãƒ‰ãŒå‹•ã„ã¦ â†’ plan ã« ["é€šçŸ¥åˆ¶é™ã‚’èª¿ã¹ã‚‹", "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰åˆ¶é™ã‚’èª¿ã¹ã‚‹"] ã¿ãŸã„ãªã®ãŒå…¥ã‚‹
      3. execute_subtasks ãŒ plan ã®å„é …ç›®ã‚’ ä¸¦åˆ—ã§ å®Ÿè¡Œã—ã¦ â†’ subtask_results ã«çµæœãŒæºœã¾ã‚‹
      4. create_answer ãŒå…¨ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã®çµæœã‚’ã¾ã¨ã‚ã¦ â†’ last_answer ã«æœ€çµ‚å›ç­”ãŒå…¥ã‚‹
      5. result ã«æœ€çµ‚çŠ¶æ…‹ãŒè¿”ã£ã¦ãã‚‹ï¼
     */
    const app = this.createGraph();

    const result = await app.invoke({
      question, // ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•æ–‡ï¼ˆå…¥åŠ›ï¼‰
      current_step: 0, // ä»Šä½•ç•ªç›®ã®ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã‹ï¼ˆæœ€åˆã ã‹ã‚‰0ï¼‰
      plan: [], // è¨ˆç”»ï¼ˆã¾ã ç©ºã€create_planãƒãƒ¼ãƒ‰ã§åŸ‹ã¾ã‚‹ï¼‰
      last_answer: '', // æœ€çµ‚å›ç­”ï¼ˆã¾ã ç©ºã€create_answerãƒãƒ¼ãƒ‰ã§åŸ‹ã¾ã‚‹ï¼‰
    });

    return {
      question,
      plan: { subtasks: result.plan },
      subtasks: result.subtask_results,
      answer: result.last_answer,
    };
  }
}
